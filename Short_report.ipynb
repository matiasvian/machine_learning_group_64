{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Group 64\n",
    "\n",
    "## Team Members\n",
    "\n",
    "* Martin Tischler - \n",
    "* Matias Johansen Vian - 494807\n",
    "* Nicolas Roger Bon - \n",
    "\n",
    "<h2>LGBMRegression</h2>\n",
    "\n",
    "LGBMRegression is a boosting framework that uses tree based learning algorithms. The model is recommended for large data sets of over 10 000 entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd \n",
    "import statsmodels.tsa.arima.model as arima\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "# import neptunecontrib.monitoring.skopt as sk_utils\n",
    "from neptune.new.integrations.lightgbm import NeptuneCallback, create_booster_summary\n",
    "# import skopt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(str(os.path.abspath('')) + '/data/beer_test.csv', parse_dates=['Date'])      # id,       Date,       ts_id,      isPromo\n",
    "train_data = pd.read_csv(str(os.path.abspath('')) + '/data/beer_train.csv', parse_dates=['Date'])    # id,       Date,       ts_id,      isPromo,    Sales\n",
    "stores = pd.read_csv(str(os.path.abspath('')) + '/data/id_store_sku.csv')      # ts_id,    Store,      SKU\n",
    "features = pd.read_csv(str(os.path.abspath('')) + '/data/sku_features.csv')    # SKU,      Segment,    Pack,       Product,    Brand,  Volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating feature sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df, sku_features, id_map):\n",
    "    '''\n",
    "    Feature generation.\n",
    "    '''\n",
    "    \n",
    "    # Add metadata\n",
    "    df = pd.merge(df, id_map, how='left', on='ts_id')\n",
    "    df = pd.merge(df, sku_features, how='left', on='SKU')\n",
    "\n",
    "    # Time features\n",
    "    df['day_of_month'] = df['Date'].dt.day\n",
    "    df['day_of_week'] = df['Date'].dt.weekday\n",
    "    df['month'] = df['Date'].dt.month\n",
    "    df['year'] = df['Date'].dt.year\n",
    "    df['week'] = df['Date'].dt.week\n",
    "    \n",
    "    # Enlarge promo features\n",
    "    # Since we know that promo is important\n",
    "    \n",
    "    df['ts_promo'] = df['ts_id'].astype(str) + df['isPromo'].astype(str)\n",
    "    df['store_promo'] = df['Store'].astype(str) + df['isPromo'].astype(str)\n",
    "    df['segment_promo'] = df['Segment'].astype(str) + df['isPromo'].astype(str)\n",
    "    df['brand_promo'] = df['Brand'].astype(str) + df['isPromo'].astype(str)\n",
    "    df['sku_promo'] = df['SKU'].astype(str) + df['isPromo'].astype(str)\n",
    "    \n",
    "    df['dom_promo'] = df['day_of_month'].astype(str) + df['isPromo'].astype(str)\n",
    "    df['dow_promo'] = df['day_of_week'].astype(str) + df['isPromo'].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(train_features, test_features):\n",
    "    '''\n",
    "    LGBM regression based on features.\n",
    "    '''\n",
    "\n",
    "    clf = lgb.LGBMRegressor(num_leaves= 8, max_depth=4, \n",
    "                        random_state=42, \n",
    "                        silent=True, \n",
    "                        metric='rmse', \n",
    "                        n_jobs=-1, \n",
    "                        n_estimators=1000,\n",
    "                        colsample_bytree=0.95,\n",
    "                        subsample=0.6,\n",
    "                        learning_rate=0.05,\n",
    "                        num_iterations=300)\n",
    "\n",
    "    clf.fit(train_features.drop(columns = ['Sales', 'Date']), train_data['Sales'])\n",
    "\n",
    "    prediction = clf.predict(test_features.drop(columns = ['id', 'Date']))\n",
    "\n",
    "    return numpy.array(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.097253   0.83780343 0.96660902 ... 0.15087151 0.69001251 0.17233502]\n"
     ]
    }
   ],
   "source": [
    "train_features = generate_features(train_data, features, stores)\n",
    "test_features = generate_features(test_data, features, stores)\n",
    "\n",
    "# Generating categories\n",
    "for c in test_features.drop(columns = ['Date', 'id']).columns:\n",
    "    test_features[c] = test_features[c].astype('category')\n",
    "    train_features[c] = train_features[c].astype('category')\n",
    "\n",
    "predictions = regression(train_features, test_features)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "# TODO: Works in regular Python script, fix so it works here as well."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
  },
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
